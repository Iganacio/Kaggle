{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/plant-pathology-2021-fgvc8/train.csv\")\nSubmission = pd.read_csv(\"/kaggle/input/plant-pathology-2021-fgvc8/sample_submission.csv\")\nPrefix=\"/kaggle/input/plant-pathology-2021-fgvc8/train_images/\"\n\nprint(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BORRAR\ntrain=train.loc[0:1500]\nprint(train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train[\"labels\"].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert categorical variable into dummy/indicator variables\ny_train=pd.get_dummies(train[\"labels\"])\nprint(y_train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[\"scab\"] = np.where(y_train['scab frog_eye_leaf_spot']==1,1,y_train[\"scab\"])\ny_train[\"frog_eye_leaf_spot\"] = np.where(y_train['scab frog_eye_leaf_spot']==1,1,y_train[\"frog_eye_leaf_spot\"])\n\ny_train[\"scab\"] = np.where(y_train['scab frog_eye_leaf_spot complex']==1,1,y_train[\"scab\"])\ny_train[\"frog_eye_leaf_spot\"] = np.where(y_train['scab frog_eye_leaf_spot complex']==1,1,y_train[\"frog_eye_leaf_spot\"])\ny_train[\"complex\"] = np.where(y_train['scab frog_eye_leaf_spot complex']==1,1,y_train[\"complex\"])\n\ny_train[\"frog_eye_leaf_spot\"] = np.where(y_train['frog_eye_leaf_spot complex']==1,1,y_train[\"frog_eye_leaf_spot\"])\ny_train[\"complex\"] = np.where(y_train['frog_eye_leaf_spot complex']==1,1,y_train[\"complex\"])\n\ny_train[\"frog_eye_leaf_spot\"] = np.where(y_train['rust frog_eye_leaf_spot']==1,1,y_train[\"frog_eye_leaf_spot\"])\ny_train[\"rust\"] = np.where(y_train['rust frog_eye_leaf_spot']==1,1,y_train[\"rust\"])\n\ny_train[\"complex\"] = np.where(y_train['rust complex']==1,1,y_train[\"complex\"])\ny_train[\"rust\"] = np.where(y_train['rust complex']==1,1,y_train[\"rust\"])\n\ny_train[\"complex\"] = np.where(y_train['powdery_mildew complex']==1,1,y_train[\"complex\"])\ny_train[\"powdery_mildew\"] = np.where(y_train['powdery_mildew complex']==1,1,y_train[\"powdery_mildew\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=y_train.loc[:,['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust',\"scab\"]]\nprint(y_train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put a number between 0 and 18632 to visualizate\n\nNumb=274\n\nlocation=Prefix + train[\"image\"][Numb]\nprint(location)\n\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimg = mpimg.imread(location)\nimgplot = plt.imshow(img)\nplt.show()\nprint(train[\"labels\"][Numb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train=train.shape[0]\nprint(n_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the bath size and putting in variables the rest of the data.\nIMAGE_WIDTH = 512\nIMAGE_HEIGHT = 512\nIMAGE_CHANNELS = 3\nIMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n\nBATCH_SIZE = n_train#/258","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = []\nfor i in tqdm(range(0,n_train)):#train.shape[0])):\n    location=Prefix + train[\"image\"][i]\n    img = image.load_img(location, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH,IMAGE_CHANNELS), grayscale=False)\n    img = image.img_to_array(img)\n    img = img/255\n    train_image.append(img)\nX = np.array(train_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport scipy\nfrom PIL import Image\nfrom scipy import ndimage\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\nnp.random.seed(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    monitor = \"val_loss\", \n    min_delta = 0.0008, \n    patience = 40, \n    restore_best_weights = True, \n    verbose = 1\n)\n\ncallbacks = [early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n  Conv2D(filters = 32, kernel_size = (5,5), padding = \"same\", input_shape = IMAGE_SIZE),\n  Activation(\"relu\"),\n  MaxPooling2D(),\n  Dropout(0.45),\n  Conv2D(filters = 24, kernel_size = (5, 5), padding = \"same\"),\n  Activation(\"relu\"),\n  MaxPooling2D(),\n  Dropout(0.45),\n  Conv2D(filters = 128, kernel_size = (5, 5), padding = \"same\"),\n  Activation(\"relu\"),\n  MaxPooling2D(),\n  Conv2D(filters = 256, kernel_size = (5, 5), padding = \"same\"),\n  Activation(\"relu\"),\n  MaxPooling2D(),\n  Dropout(0.45),\n  Flatten(),\n  Dense(32),\n  Activation(\"relu\"),\n  Dropout(0.45),\n  Dense(6, activation = \"softmax\"),\n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = to_categorical(y_train)\ny=y[:,:,1]\nprint(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_test, y_train2, y_test = train_test_split(X, y, random_state=42, test_size=0.85)\n\nprint(y_train2.shape)\nprint(X_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model1=model.fit(\n    x = X_train,\n    y= y_train2,\n    steps_per_epoch = n_train // BATCH_SIZE,\n    epochs = 250, \n    validation_data = (X_test, y_test), \n    callbacks = callbacks\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = Model1.history\nfig, ax = plt.subplots(figsize = (15,8))   \nax.grid(True)\nax = fig.add_subplot(1, 2, 1)\nax.plot(hist['loss'], lw=2)\nax.set_title('Training loss', size=15)\nax.set_xlabel('Epoch', size=15)\nax.tick_params(axis='both', which='major', labelsize=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(hist['accuracy'], lw=2)\nax.set_title('Training accuracy', size=15)\nax.set_xlabel('Epoch', size=15)\nax.tick_params(axis='both', which='major', labelsize=15)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test)\nprint(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.argmax(predictions, axis = 1)\nprint(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_train)\nprint(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}